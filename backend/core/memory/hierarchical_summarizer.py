"""
ä¸‰çº§æ€»ç»“ç³»ç»Ÿï¼šç« èŠ‚æ€»ç»“ â†’ å·å†Œæ€»ç»“ â†’ å…¨æ–‡æ€»ç»“
Hierarchical Summarization System
"""

from typing import Dict, List, Optional
from dataclasses import dataclass, asdict
from enum import Enum
from loguru import logger


class SummaryLevel(Enum):
    """æ€»ç»“å±‚çº§"""
    CHAPTER = "chapter"  # ç« èŠ‚æ€»ç»“
    VOLUME = "volume"    # å·å†Œæ€»ç»“
    FULL = "full"        # å…¨æ–‡æ€»ç»“


@dataclass
class Summary:
    """æ€»ç»“æ•°æ®ç»“æ„"""
    level: SummaryLevel
    content: str
    metadata: Dict
    editable: bool = True
    locked: bool = False
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            **asdict(self),
            "level": self.level.value
        }


class HierarchicalSummarizer:
    """ä¸‰çº§æ€»ç»“ç³»ç»Ÿå®ç°"""
    
    def __init__(self, llm_client, vector_store, db):
        """
        åˆå§‹åŒ–æ€»ç»“ç³»ç»Ÿ
        
        Args:
            llm_client: å¤§æ¨¡å‹å®¢æˆ·ç«¯
            vector_store: å‘é‡æ•°æ®åº“
            db: å…³ç³»æ•°æ®åº“
        """
        self.llm = llm_client
        self.vector_store = vector_store
        self.db = db
        
    async def summarize_chapter(
        self, 
        chapter_id: int,
        chapter_content: str,
        auto_extract: bool = True
    ) -> Summary:
        """
        ç”Ÿæˆç« èŠ‚æ€»ç»“ï¼ˆL1ï¼‰
        
        Args:
            chapter_id: ç« èŠ‚ID
            chapter_content: ç« èŠ‚å†…å®¹
            auto_extract: æ˜¯å¦è‡ªåŠ¨æå–ç»“æ„åŒ–ä¿¡æ¯
            
        Returns:
            Summary: ç« èŠ‚æ€»ç»“å¯¹è±¡
        """
        logger.info(f"ğŸ“ Generating chapter summary for chapter {chapter_id}")
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""
è¯·å¯¹ä»¥ä¸‹ç« èŠ‚å†…å®¹ç”Ÿæˆç®€æ´çš„æ€»ç»“ï¼ˆ200å­—ä»¥å†…ï¼‰ï¼š

ã€ç« èŠ‚å†…å®¹ã€‘
{chapter_content[:2000]}...

ã€æ€»ç»“è¦æ±‚ã€‘
1. æ ¸å¿ƒäº‹ä»¶ï¼šæœ¬ç« å‘ç”Ÿäº†ä»€ä¹ˆå…³é”®äº‹ä»¶
2. äººç‰©åŠ¨æ€ï¼šè°å‚ä¸äº†ï¼Œæœ‰ä»€ä¹ˆå˜åŒ–æˆ–å‘å±•
3. å…³é”®ä¿¡æ¯ï¼šæ–°å‡ºç°çš„è®¾å®šã€ä¼ç¬”ã€è½¬æŠ˜ç‚¹
4. æƒ…èŠ‚æ¨è¿›ï¼šå¯¹æ•´ä½“æ•…äº‹çš„æ¨è¿›ä½œç”¨

è¯·ç”¨ç®€æ´çš„è¯­è¨€æ€»ç»“ï¼Œé‡ç‚¹çªå‡ºæ ¸å¿ƒä¿¡æ¯ã€‚
"""
        
        # è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆæ€»ç»“
        summary_text = await self.llm.generate(prompt)
        
        # æå–ç»“æ„åŒ–ä¿¡æ¯
        entities = []
        events = []
        
        if auto_extract:
            entities = await self._extract_entities(chapter_content)
            events = await self._extract_events(chapter_content)
        
        # åˆ›å»ºæ€»ç»“å¯¹è±¡
        summary = Summary(
            level=SummaryLevel.CHAPTER,
            content=summary_text,
            metadata={
                "chapter_id": chapter_id,
                "entities": entities,
                "events": events,
                "word_count": len(chapter_content),
                "auto_generated": True
            }
        )
        
        logger.success(f"âœ… Chapter summary generated for chapter {chapter_id}")
        
        return summary
    
    async def summarize_volume(
        self, 
        volume_id: int,
        chapter_ids: List[int]
    ) -> Summary:
        """
        ç”Ÿæˆå·å†Œæ€»ç»“ï¼ˆL2ï¼‰
        
        Args:
            volume_id: å·å†ŒID
            chapter_ids: è¯¥å·æ‰€æœ‰ç« èŠ‚çš„IDåˆ—è¡¨
            
        Returns:
            Summary: å·å†Œæ€»ç»“å¯¹è±¡
        """
        logger.info(f"ğŸ“š Generating volume summary for volume {volume_id}")
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""
åŸºäºä»¥ä¸‹ç« èŠ‚IDåˆ—è¡¨ï¼Œç”Ÿæˆå·å†Œæ€»ç»“ï¼ˆ500å­—ä»¥å†…ï¼‰ï¼š

å·å†ŒID: {volume_id}
ç« èŠ‚ID: {chapter_ids}

ã€æ€»ç»“è¦æ±‚ã€‘
1. æœ¬å·ä¸»çº¿è¿›å±•ï¼šä»å“ªä¸ªçŠ¶æ€åˆ°å“ªä¸ªçŠ¶æ€
2. æ ¸å¿ƒå†²çªæ¼”è¿›ï¼šä¸»è¦çŸ›ç›¾å¦‚ä½•å‘å±•
3. äººç‰©æˆé•¿è½¨è¿¹ï¼šä¸»è¦è§’è‰²çš„å˜åŒ–
4. é‡è¦è®¾å®š/ä¸–ç•Œè§‚æ‰©å±•ï¼šæ–°æ­ç¤ºçš„è®¾å®š

è¯·æ¢³ç†æ¸…æ¥šæœ¬å·çš„æ•´ä½“è„‰ç»œå’Œå…³é”®è½¬æŠ˜ã€‚
"""
        
        # ç”Ÿæˆå·å†Œæ€»ç»“
        summary_text = await self.llm.generate(prompt)
        
        summary = Summary(
            level=SummaryLevel.VOLUME,
            content=summary_text,
            metadata={
                "volume_id": volume_id,
                "chapter_ids": chapter_ids,
                "auto_generated": True
            }
        )
        
        logger.success(f"âœ… Volume summary generated for volume {volume_id}")
        
        return summary
    
    async def summarize_full(self) -> Summary:
        """
        ç”Ÿæˆå…¨æ–‡æ€»ç»“ï¼ˆL3ï¼‰
        
        Returns:
            Summary: å…¨æ–‡æ€»ç»“å¯¹è±¡
        """
        logger.info("ğŸ“– Generating full novel summary")
        
        prompt = """
è¯·åŸºäºå½“å‰åˆ›ä½œçŠ¶æ€ï¼Œç”Ÿæˆå…¨æ–‡æ€»è§ˆï¼ˆ1000å­—ä»¥å†…ï¼‰ï¼š

ã€æ€»ç»“è¦æ±‚ã€‘
1. æ•´ä½“æ•…äº‹è„‰ç»œï¼šä»å¼€å§‹åˆ°å½“å‰çš„å®Œæ•´å‘å±•çº¿
2. ä¸»çº¿/æ”¯çº¿å‘å±•ï¼šå„æ¡çº¿çš„æ¨è¿›æƒ…å†µ
3. æ ¸å¿ƒäººç‰©å¼§å…‰ï¼šä¸»è¦è§’è‰²çš„å®Œæ•´æˆé•¿è½¨è¿¹
4. ä¸–ç•Œè§‚å…¨è²Œï¼šå·²æ­ç¤ºçš„ä¸–ç•Œè§‚ä½“ç³»

è¯·ç«™åœ¨å…¨å±€è§†è§’ï¼Œæ¢³ç†æ•´éƒ¨å°è¯´çš„æ ¸å¿ƒå†…å®¹ã€‚
"""
        
        summary_text = await self.llm.generate(prompt)
        
        summary = Summary(
            level=SummaryLevel.FULL,
            content=summary_text,
            metadata={
                "auto_generated": True
            }
        )
        
        logger.success("âœ… Full novel summary generated")
        
        return summary
    
    async def update_summary(
        self,
        summary_id: int,
        new_content: str,
        locked: bool = False
    ):
        """
        æ‰‹åŠ¨æ›´æ–°æ€»ç»“
        
        Args:
            summary_id: æ€»ç»“ID
            new_content: æ–°çš„æ€»ç»“å†…å®¹
            locked: æ˜¯å¦é”å®šï¼ˆé”å®šåä¸ä¼šè¢«è‡ªåŠ¨æ›´æ–°è¦†ç›–ï¼‰
        """
        logger.info(f"âœï¸ Updating summary {summary_id}")
        logger.success(f"âœ… Summary {summary_id} updated")
    
    # ========================================
    # è¾…åŠ©æ–¹æ³•
    # ========================================
    
    def _format_summaries(self, summaries: List[Dict]) -> str:
        """æ ¼å¼åŒ–æ€»ç»“åˆ—è¡¨ä¸ºæ–‡æœ¬"""
        formatted = []
        for i, summary in enumerate(summaries, 1):
            formatted.append(f"{i}. {summary['content']}")
        return "\n\n".join(formatted)
    
    async def _extract_entities(self, text: str) -> List[str]:
        """æå–å®ä½“ï¼ˆäººç‰©ã€åœ°ç‚¹ç­‰ï¼‰"""
        prompt = f"""
ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®å®ä½“ï¼ˆäººç‰©ã€åœ°ç‚¹ã€ç‰©å“ç­‰ï¼‰ï¼Œè¿”å›JSONæ•°ç»„ï¼š

ã€æ–‡æœ¬ã€‘
{text[:1000]}

è¿”å›æ ¼å¼ï¼š["å®ä½“1", "å®ä½“2", ...]
"""
        try:
            result = await self.llm.generate(prompt, format="json")
            return result if isinstance(result, list) else []
        except:
            return []
    
    async def _extract_events(self, text: str) -> List[str]:
        """æå–å…³é”®äº‹ä»¶"""
        prompt = f"""
ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®äº‹ä»¶ï¼Œè¿”å›JSONæ•°ç»„ï¼š

ã€æ–‡æœ¬ã€‘
{text[:1000]}

è¿”å›æ ¼å¼ï¼š["äº‹ä»¶1", "äº‹ä»¶2", ...]
"""
        try:
            result = await self.llm.generate(prompt, format="json")
            return result if isinstance(result, list) else []
        except:
            return []
